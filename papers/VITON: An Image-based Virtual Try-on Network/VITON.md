# ■ 論文
- 論文タイトル："VITON: An Image-based Virtual Try-on Network"
- 論文リンク：https://arxiv.org/abs/1711.08447
- 論文投稿日付：
- 被引用数（記事作成時点）：xxx 件
- 著者（組織）：
- categories：

# ■ 概要（何をしたか？）

## Abstract

- We present an image-based VIirtual Try-On Network (VITON) without using 3D information in any form, which seamlessly transfers a desired clothing item onto the corresponding region of a person using a coarse-to-fine strategy. Conditioned upon a new clothing-agnostic yet descriptive person representation, our framework first generates a coarse synthesized image with the target clothing item over- laid on that same person in the same pose. We further enhance the initial blurry clothing area with a refinement network. The network is trained to learn how much detail to utilize from the target clothing item, and where to apply to the person in order to synthesize a photo-realistic image in which the target item deforms naturally with clear visual patterns. Experiments on our newly collected dataset demonstrate its promise in the image-based virtual try-on task over state-of-the-art generative models.
    - 任意の形式の3D情報を使用せずに、画像ベースの仮想試着ネットワーク（VITON）を提示します。これは、粗から密への戦略を使用して、目的の衣服を人の対応する領域にシームレスに転送します。 新しい衣類に依存しないが説明的な人物表現に基づいて、私たちのフレームワークはまず、同じポーズで同じ人物にターゲット衣類アイテムがオーバーレイされた粗い合成画像を生成します。 洗練されたネットワークを使用して、最初のぼやけた衣服の領域をさらに強化します。 ネットワークは、対象の衣料品からどのくらいのディテールを利用するか、そして対象品が明確な視覚パターンで自然に変形するフォトリアリスティックな画像を合成するために人に適用する場所を学習するように訓練されます。 新しく収集されたデータセットの実験は、最先端の生成モデルを介した画像ベースの仮想試着タスクでの約束を示しています。
    
# ■ イントロダクション（何をしたいか？）

## x. Introduction

- 第１パラグラフ

---

- 第２パラグラフ

# ■ 結論

## x. Conclusion


# ■ 何をしたか？詳細

## x. 論文の項目名


# ■ 実験結果（主張の証明）・議論（手法の良し悪し）・メソッド（実験方法）

## x. 論文の項目名


# ■ 関連研究（他の手法との違い）

## x. Related Work


