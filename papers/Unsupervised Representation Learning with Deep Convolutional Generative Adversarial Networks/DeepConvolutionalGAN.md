## 0. 論文
- 論文リンク：[[1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)
- 論文投稿日付：2015/11/19(v1), 2016/xx/07(v2)
- 著者：Alec Radford, Luke Metz, Soumith Chintala
- 分類 [Subjects]：Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)

## 概要 [Abstract]

- In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. 
    - 最近では、CNN の構造をもつ教師あり学習が、コンピュータービジョンのアプリケーションにおいて、莫大に採用 [adoption] されている。

- Comparatively, unsupervised learning with CNNs has received less attention.
    - 比較的 [Comparatively]、CNN の構造を持つ教師なし学習は、あまり注目 [attention] されていない。

- In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. 
    - この論文では、我々は、教師あり学習と教師なし学習のための CNN の成功の間にあるギャップをなくす [bridge the gap] ことを望んでいる。

- We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning.
    - 我々は、DCGAN と呼ばれる CNN のクラスを紹介する。
    - これは、特定の [certain] アーキテクチャ的な制約を持ち、教師なし学習のための強い候補であるということを実証する。

- Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator.
    - <font color="Pink">様々なデータセットの学習で、我々は、CNN 構造をもつ敵対的ネットワークのペアが、生成器と識別器の両方のシーンの対象部分からの表現の階層を学習するという説得力のある [convincing] 証拠を見せる</font>

- Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.
    - 加えて、我々は、（タスクの）適用性を一般的な画像表現として実証するような新型の [novel] タスクのために、学習された特徴量を使用する。

## イントロダクション

## 結論
