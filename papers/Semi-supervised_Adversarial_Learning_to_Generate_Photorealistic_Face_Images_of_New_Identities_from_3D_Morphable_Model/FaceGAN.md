# ■ 論文
- 論文タイトル："Semi-supervised Adversarial Learning to Generate Photorealistic Face Images of New Identities from 3D Morphable Model"
- 論文リンク：https://arxiv.org/abs/1804.03675
- 論文投稿日付：2018/04/10
- 著者（組織）：
- categories：

# ■ 概要（何をしたか？）

## Abstract

- We propose a novel end-to-end semi-supervised adversarial framework to generate photorealistic face images of new identities with wide ranges of expressions, poses, and illuminations conditioned by a 3D morphable model.
    - 我々は、広範囲の表情、ポーズ、および3Dモーフィングモデルによって調整された照明を用いて、新しいアイデンティティの写実的な顔画像を生成するための、新しい end-to-end の半教師あり敵対的フレームワークを提案する。

- Previous adversarial style-transfer methods either supervise their networks with large volume of paired data or use unpaired data with a highly under-constrained two-way generative framework in an unsupervised fashion. 
    - 以前の敵対的な style-transfer 手法では、ネットワークを大量のペアデータを教師あり（で学習する）か、
    - 教師なしの形式において非常に制約の少ない双方向 [two-way] の生成フレームワークで、ペアデータを使用していました。

- We introduce pair- wise adversarial supervision to constrain two-way domain adaptation by a small number of paired real and synthetic images for training along with the large volume of unpaired data.
    - 本研究では、大量のペア付けされていないデータに加えて、学習用の少数のペア付けされた本物画像と合成画像によって、双方向のドメイン適応を制約するために、対をなす敵対的監視 [pair- wise adversarial supervision] を導入する。

- Extensive qualitative and quantitative experiments are performed to validate our idea.
    - 私たちの考えを検証するために、広範囲の定性的および定量的実験が行われます。

- Generated face images of new identities contain pose, lighting and expression diversity and qualitative results show that they are highly constraint by the synthetic input image while adding photorealism and retaining identity information.
    - 新しいアイデンティティの生成された顔画像はポーズ、照明および表情の多様性を含み、
    - 定性的結果は、それらがフォトリアリズムを追加し、アイデンティティ情報を保持する一方で、
    - それらが、合成入力画像によって強く制約されていることを示す。

- We combine face images generated by the proposed method with the real data set to train face recognition algorithms.
    - 我々は、顔認識アルゴリズムを学習させるために、提案手法により生成された顔画像と本物のデータセットを組み合わせる。

- We evaluated the model on two challenging data sets: LFW and IJB-A.
    - LFWとIJB-Aという2つの難しいデータセットでモデルを評価しました。

- We observe that the generated images from our framework consistently improves over the performance of deep face recognition network trained with Oxford VGG Face dataset and achieves comparable results to the state-of-the-art.
    - 私達は私達のフレームワークから生成された画像が一貫してOxford VGG Faceデータセットで訓練された深層顔認識ネットワークの性能を改善し、そして SOAT に匹敵する結果を達成することを観察します。

# ■ イントロダクション（何をしたいか？）

## 1. 論文の項目名 (Introduction)

- Deep learning has shown an great improvement in performance of several computer vision tasks [37,19,15,11,12,58] including face recognition [33,41,54,30,53] in the recent years.

- This was mainly thanks to the availability of large-scale datasets.

- Yet the performance is often limited by the volume and the variations of training examples.

- Larger and wider datasets usually improve the generalization and overall performance of the model [41,1].

---

- The process of collecting and annotating training examples for every specific computer vision task is laborious and non-trivial.
    - 特定のコンピュータビジョンタスクごとにトレーニング例を収集して注釈を付けるプロセスは、面倒で [laborious] 簡単でない [non-trivial]。

- To overcome this challenge, additional synthetic training examples along with limited real training examples can be utilised to train the model.
    - この課題を克服するために、限られた本物（データでの）学習例と共に、追加の合成（画像データでの）学習例を利用してモデルを学習することができる。

- Some of the recent works such as 3D face reconstruction [38], gaze estimation [61,52], human pose, shape and motion estimation [49] etc. use additional synthetic images generated from 3D models to train deep networks.
    - 3D顔再構成[38]、視線推定[61,52]、人間の姿勢、形状および動き推定[49]などの最近の研究のいくつかは、深層ネットワークを学習するために、3Dモデルから生成された追加の合成画像を使用する。

- One can generate synthetic face images using a 3D morphable model (3DMM) [3] by manipulating identity, expression, illumination, and pose parameters.
    - アイデンティティ、表情、照明、ポーズのパラメータを操作する [manipulating] ことで、3Dモーフィングモデル（3DMM）[3]を使用して合成顔画像を生成できます。

- However, the resulting images are not photorealistic enough to be suitable for in-the-wild face recognition tasks.
    - しかしながら、結果として得られる画像は、野外での？ [in-the-wild] 顔認識タスクに適しているほど十分に写実的ではない。

- It is beacause the information of real face scans is compressed by the 3DMM and the graphical engine that models illumination and surface is not perfectly accurate.
    - それは、本物の顔面のスキャン情報が3DMMによって圧縮されていることと、
    - 照明と表面をモデル化するグラフィカルエンジンが完全に正確ではないためです。

- Thus, the main challenge of using synthetic data obtained from 3DMM model is the discrepancy in nature and quality of synthetic and real images which pose the problem of domain adaptation [34].
    - したがって、3DMMモデルから得られた合成データを使用することの主な課題は、ドメイン適応の問題を引き起こす [pose] ような、合成画像と本物画像の性質 [nature] と品質の食い違い [discrepancy] です[34]。

- Recently, adversarial training methods [42,44,10] become popular to mitigate such challenges.
    - 最近、そのような課題を軽減する [mitigate] ために、敵対的な学習方法[42、44、10]が普及しています。

---

- Generative Adversarial Network (GAN), introduced by Goodfellow et al. [17], and its variants [35,24,2,13] are quite successful in generating realistic images.

- However, in practice, GANs are likely to stuck in mode collapse for large scale image generation.

- They are also unable to produce images that are 3D coherent and globally consistent [17].
    - 彼らはまた、3Dで大域的に一貫した画像を作成することはできません[17]。

- To overcome these drawbacks, we propose a semi-supervised adversarial learning framework to synthesize photorealistic face images of new identities with numerous data variation supplied by a 3DMM.
    - **これらの欠点 [drawbacks] を克服するために、我々は、３ＤＭＭによって供給される多数のデータ変動を用いて、新しいアイデンティティの写実的な顔画像を合成するための半教師付き敵対的学習フレームワークを提案する。**

- We address these shortcomings by exciting a generator network with synthetic images sampled from 3DMM and transforming them into photorealistic domain using adversarial training as a bridge.
    - 3DMMからサンプリングされた合成画像で、生成器ネットワークを刺激することによって、
    - またブリッジとして敵対的学習を使用して、それらをフォトリアリスティックドメインに変換することによって、
    - これらの欠点 [shortcomings] に対処します。

- Unlike most of the existing works that excite their generators with a noise vector [35,2], we feed our generator network by synthetic face images.
    - **ノイズベクトルでそれらのジェネレータを刺激する既存の研究のほとんどとは異なり[35、2]、我々は合成顔画像によって我々のジェネレータネットワークを供給します。**

- Such a strong constraint naturally helps in avoiding the mode collapse problem, one of the main challenges faced by the current GAN methods.
    - そのような強い制約は、現在のＧＡＮ方法が直面する主な課題の１つであるモード崩壊問題を回避するのに自然に役立つ。

- Fig. 1 shows the general overview of the proposed method. We discuss the proposed method in more details in Sec. 3.
    - 提案手法の概要を図1に示す。 提案手法については、セクション３ででさらに詳しく議論する。

---

![image](https://user-images.githubusercontent.com/25688193/61192596-8679c580-a6f0-11e9-97bd-78f207a47279.png)

- > Fig. 1: Our approach aims to synthesize photorealistic images conditioned by a given synthetic image by 3DMM.
    - > 図１：我々のアプローチは、３ＤＭＭによって与えられた合成画像で条件付けされた写実的な画像を合成することを目的としている。

- > It regularizes cycle consistency [63] by introducing an additional adversarial game between the two generator networks in an unsupervised fashion.
    - > それは、教師なし形式で、2つのジェネレータネットワークの間に追加の敵対的なゲームを導入することによって cycle consistency  を正則化する[63]。

> CycleGAN の cycle consistency

- > Thus the under-constraint cycle loss is supervised to have correct matching between the two domains by the help of a limited number of paired data.
    - > したがって、制限されていないサイクル損失は、限られた数のペア付けされたデータの助けを借りることによって、2つのドメイン間で、正しく一致するように管理されます。

- > We also encourage the generator to preserve face identity by a set-based supervision through a pretrained classification network.
    - > 私達はまた生成器が、事前学習された分類ネットワークを通して、集合ベースの監査？ [set-based supervision] によって、顔のアイデンティティを保存することを促進します。

---

- In this paper, we address the challenge of generating photorealistic face images from 3DMM rendered faces of different identities with arbitrary poses, expressions, and illuminations.
    - 本論文では、任意のポーズ・表情・照明をもつ、異なるアイデンティティの3DMMでレンダリングされた顔から、フォトリアリスティックな顔画像を生成するという課題に取り組みます。

- We formulate this problem as a domain adaptation problem i.e. aligning the 3DMM rendered face domain into realistic face domain.
    - この問題をドメイン適応問題として定式化する。
    - 即ち、３ＤＭＭレンダリングされた顔ドメインを現実的な顔ドメインに整列させること。

- One of the previous works closest to ours [22] address style transfer problem between a pair of domains with classical conditional GAN.
    - 我々の手法に最も近い以前の研究は、古典的なcGANで一対のドメイン間の style transfer に取り組み。

- The major bottleneck of this method is, it requires a large number of paired examples from both domains which are hard to collect.
    - この方法の主なボトルネックは、収集が困難な両方のドメインから多数のペアの例を必要とすることです。

- CycleGAN [63], another recent method and closest to our work, proposes a two-way GAN framework for unsupervised image-to-image translation.
    - CycleGAN [63] は、も我々の研究に最も近い最近の方法の別の１つで、教師なしの image-to-image 変換のための双方向GANフレームワークを提案します。

- However, the cycle consistency loss proposed in their method is satisfied as long as the transitivity of the two mapping networks is maintained.
    - しかしながら、それらの方法において提案された cycle consistency loss は、２つのマッピングネットワークの転移性が維持される限り満足される。

- Thus, the resulting mapping is not guaranteed to produce the intended transformation.
    - したがって、結果として得られるマッピングが意図した変換を生成することは保証されません。

- To overcome the drawbacks of these methods [22,63], we propose to use a small amount of paired data to train an inverse mapping network as a matching aware discriminator.
    - **これらの方法の欠点を克服するために[22] [63]、マッチング対応識別器 [matching aware discriminator] として逆写像ネットワークを訓練するために少量の対データを使用することを提案する。**

- In the proposed method, the inverse mapping network plays the role of both the generator and the discriminator.
    - **提案手法では、逆写像ネットワークが生成器と識別器の両方の役割を果たす。**

- To the best of our knowledge, this is the first attempt for adversarial semi-supervised style translation for an application with such limited paired data.
    - 私たちの知る限りでは、これはそのような限られた対データを持つアプリケーションのための敵対的半教師付き Style Transfer の最初の試みです。

---

- Adding realism to the synthetic face images and preserving their identity information is a challenging problem.
    - 合成顔画像にリアリズムを追加し、それらの識別情報を保存することは困難な問題である。

- Although synthetic input images, 3DMM rendered faces, contain distinct face identities, the distinction between them vanishes as a result of the virtue of non-linear transformations while the discriminator encourages realism.
    - 合成入力画像、３ＤＭＭレンダリングされた顔は、全く別の [distinct] 顔の同一性を含むが、
    - それらの間の区別は、識別器がリアリズムを奨励する一方で、非線形変換のおかげで [virtue of] 消滅する。
    
- To tackle such problem, prior works either employ a separate pre-trained network [57] or embed Identity labels (id) [46] into the discriminator.
    - そのような問題に取り組むために、これまでの研究では、事前学習された別れた [separate] ネットワーク[57]を使用するか、識別器に識別ラベル（id）[46]を埋め込んでいます。

- Unlike existing works, which are focused on generating new images of existing identities, we are interested in generating multiple images of new identities itself. 
    - 既存のアイデンティティの新しい画像を生成することに焦点を当てている既存の研究とは異なり、私たちは新しいアイデンティティの複数の画像自体を生成することに興味を持っています。

- Therefore, such techniques are not directly applicable to our problem.

- To address this challenge, we propose to use set-based center [50] and pushing loss functions [16] on top of a pre-trained face embedding network.

- This will keep track of the changing average of embeddings of generated images belonging to same identity (i.e. centroids).

- In this way identity preservation becomes adaptive to changing feature space during the training of the generator network unlike softmax layer that converges very quickly at the beginning of the training before meaningful images are generated.

---

- Our contributions can be summarized as follows:

- We propose a novel end-to-end adversarial training framework to generate photorealistic face images of new identities constrained by synthetic 3DMM images with identity, pose, illumination and expression diversity. The resulting synthetic face images are visually plausible and can be used to boost face recognition as additional training data or any other graphical purposes.

- We propose a novel semi-supervised adversarial style transfer approach that trains an inverse mapping network as a discriminator with paired synthetic-real images.

- Weemployanovelset-basedlossfunctiontopreserveconsistencyamongunknown identities during GAN training.


# ■ 結論

## x. 論文の項目名 (Conclusion)


# ■ 何をしたか？詳細

## x. 論文の項目名


# ■ 実験結果（主張の証明）・議論（手法の良し悪し）・メソッド（実験方法）

## x. 論文の項目名


# ■ 関連研究（他の手法との違い）

## x. 論文の項目名（Related Work）


