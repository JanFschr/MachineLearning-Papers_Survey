# ■ 論文
- 論文タイトル："Semi-supervised Adversarial Learning to Generate Photorealistic Face Images of New Identities from 3D Morphable Model"
- 論文リンク：https://arxiv.org/abs/1804.03675
- 論文投稿日付：2018/04/10
- 著者（組織）：
- categories：

# ■ 概要（何をしたか？）

## Abstract

- We propose a novel end-to-end semi-supervised adversarial framework to generate photorealistic face images of new identities with wide ranges of expressions, poses, and illuminations conditioned by a 3D morphable model.
    - 我々は、広範囲の表情、ポーズ、および3Dモーフィングモデルによって調整された照明を用いて、新しいアイデンティティの写実的な顔画像を生成するための、新しい end-to-end の半教師あり敵対的フレームワークを提案する。

- Previous adversarial style-transfer methods either supervise their networks with large volume of paired data or use unpaired data with a highly under-constrained two-way generative framework in an unsupervised fashion. 
    - 以前の敵対的な style-transfer 手法では、ネットワークを大量のペアデータを教師あり（で学習する）か、
    - 教師なしの形式において非常に制約の少ない双方向 [two-way] の生成フレームワークで、ペアデータを使用していました。

- We introduce pair- wise adversarial supervision to constrain two-way domain adaptation by a small number of paired real and synthetic images for training along with the large volume of unpaired data.
    - 本研究では、大量のペア付けされていないデータに加えて、学習用の少数のペア付けされた本物画像と合成画像によって、双方向のドメイン適応を制約するために、対をなす敵対的監視 [pair- wise adversarial supervision] を導入する。

- Extensive qualitative and quantitative experiments are performed to validate our idea.
    - 私たちの考えを検証するために、広範囲の定性的および定量的実験が行われます。

- Generated face images of new identities contain pose, lighting and expression diversity and qualitative results show that they are highly constraint by the synthetic input image while adding photorealism and retaining identity information.
    - 新しいアイデンティティの生成された顔画像はポーズ、照明および表情の多様性を含み、
    - 定性的結果は、それらがフォトリアリズムを追加し、アイデンティティ情報を保持する一方で、
    - それらが、合成入力画像によって強く制約されていることを示す。

- We combine face images generated by the proposed method with the real data set to train face recognition algorithms.
    - 我々は、顔認識アルゴリズムを学習させるために、提案手法により生成された顔画像と本物のデータセットを組み合わせる。

- We evaluated the model on two challenging data sets: LFW and IJB-A.
    - LFWとIJB-Aという2つの難しいデータセットでモデルを評価しました。

- We observe that the generated images from our framework consistently improves over the performance of deep face recognition network trained with Oxford VGG Face dataset and achieves comparable results to the state-of-the-art.
    - 私達は私達のフレームワークから生成された画像が一貫してOxford VGG Faceデータセットで訓練された深層顔認識ネットワークの性能を改善し、そして SOAT に匹敵する結果を達成することを観察します。

# ■ イントロダクション（何をしたいか？）

## 1. 論文の項目名 (Introduction)

- Deep learning has shown an great improvement in performance of several computer vision tasks [37,19,15,11,12,58] including face recognition [33,41,54,30,53] in the recent years.

- This was mainly thanks to the availability of large-scale datasets.

- Yet the performance is often limited by the volume and the variations of training examples.

- Larger and wider datasets usually improve the generalization and overall performance of the model [41,1].

---

- The process of collecting and annotating training examples for every specific computer vision task is laborious and non-trivial.
    - 特定のコンピュータビジョンタスクごとにトレーニング例を収集して注釈を付けるプロセスは、面倒で [laborious] 簡単でない [non-trivial]。

- To overcome this challenge, additional synthetic training examples along with limited real training examples can be utilised to train the model.
    - この課題を克服するために、限られた本物（データでの）学習例と共に、追加の合成（画像データでの）学習例を利用してモデルを学習することができる。

- Some of the recent works such as 3D face reconstruction [38], gaze estimation [61,52], human pose, shape and motion estimation [49] etc. use additional synthetic images generated from 3D models to train deep networks.
    - 3D顔再構成[38]、視線推定[61,52]、人間の姿勢、形状および動き推定[49]などの最近の研究のいくつかは、深層ネットワークを学習するために、3Dモデルから生成された追加の合成画像を使用する。

- One can generate synthetic face images using a 3D morphable model (3DMM) [3] by manipulating identity, expression, illumination, and pose parameters.
    - アイデンティティ、表情、照明、ポーズのパラメータを操作する [manipulating] ことで、3Dモーフィングモデル（3DMM）[3]を使用して合成顔画像を生成できます。

- However, the resulting images are not photorealistic enough to be suitable for in-the-wild face recognition tasks.
    - しかしながら、結果として得られる画像は、野外での？ [in-the-wild] 顔認識タスクに適しているほど十分に写実的ではない。

- It is beacause the information of real face scans is compressed by the 3DMM and the graphical engine that models illumination and surface is not perfectly accurate.
    - それは、本物の顔面のスキャン情報が3DMMによって圧縮されていることと、
    - 照明と表面をモデル化するグラフィカルエンジンが完全に正確ではないためです。

- Thus, the main challenge of using synthetic data obtained from 3DMM model is the discrepancy in nature and quality of synthetic and real images which pose the problem of domain adaptation [34].
    - したがって、3DMMモデルから得られた合成データを使用することの主な課題は、ドメイン適応の問題を引き起こす [pose] ような、合成画像と本物画像の性質 [nature] と品質の食い違い [discrepancy] です[34]。

- Recently, adversarial training methods [42,44,10] become popular to mitigate such challenges.
    - 最近、そのような課題を軽減する [mitigate] ために、敵対的な学習方法[42、44、10]が普及しています。

---

- Generative Adversarial Network (GAN), introduced by Goodfellow et al. [17], and its variants [35,24,2,13] are quite successful in generating realistic images.

- However, in practice, GANs are likely to stuck in mode collapse for large scale image generation.

- They are also unable to produce images that are 3D coherent and globally consistent [17].
    - 彼らはまた、3Dで大域的に一貫した画像を作成することはできません[17]。

- To overcome these drawbacks, we propose a semi-supervised adversarial learning framework to synthesize photorealistic face images of new identities with numerous data variation supplied by a 3DMM.
    - **これらの欠点 [drawbacks] を克服するために、我々は、３ＤＭＭによって供給される多数のデータ変動を用いて、新しいアイデンティティの写実的な顔画像を合成するための半教師付き敵対的学習フレームワークを提案する。**

- We address these shortcomings by exciting a generator network with synthetic images sampled from 3DMM and transforming them into photorealistic domain using adversarial training as a bridge.
    - 3DMMからサンプリングされた合成画像で、生成器ネットワークを刺激することによって、
    - またブリッジとして敵対的学習を使用して、それらをフォトリアリスティックドメインに変換することによって、
    - これらの欠点 [shortcomings] に対処します。

- Unlike most of the existing works that excite their generators with a noise vector [35,2], we feed our generator network by synthetic face images.
    - **ノイズベクトルでそれらのジェネレータを刺激する既存の研究のほとんどとは異なり[35、2]、我々は合成顔画像によって我々のジェネレータネットワークを供給します。**

- Such a strong constraint naturally helps in avoiding the mode collapse problem, one of the main challenges faced by the current GAN methods.
    - そのような強い制約は、現在のＧＡＮ方法が直面する主な課題の１つであるモード崩壊問題を回避するのに自然に役立つ。

- Fig. 1 shows the general overview of the proposed method. We discuss the proposed method in more details in Sec. 3.
    - 提案手法の概要を図1に示す。 提案手法については、セクション３でさらに詳しく議論する。

---

![image](https://user-images.githubusercontent.com/25688193/61192596-8679c580-a6f0-11e9-97bd-78f207a47279.png)

- > Fig. 1: Our approach aims to synthesize photorealistic images conditioned by a given synthetic image by 3DMM.
    - > 図１：我々のアプローチは、３ＤＭＭによって与えられた合成画像で条件付けされた写実的な画像を合成することを目的としている。

- > It regularizes cycle consistency [63] by introducing an additional adversarial game between the two generator networks in an unsupervised fashion.
    - > それは、教師なし形式で、2つのジェネレータネットワークの間に追加の敵対的なゲームを導入することによって cycle consistency  を正則化する[63]。

> CycleGAN の cycle consistency

- > Thus the under-constraint cycle loss is supervised to have correct matching between the two domains by the help of a limited number of paired data.
    - > したがって、制限されていないサイクル損失は、限られた数のペア付けされたデータの助けを借りることによって、2つのドメイン間で、正しく一致するように管理されます。

- > We also encourage the generator to preserve face identity by a set-based supervision through a pretrained classification network.
    - > 私達はまた生成器が、事前学習された分類ネットワークを通して、集合ベースの監査？ [set-based supervision] によって、顔のアイデンティティを保存することを促進します。

---

- In this paper, we address the challenge of generating photorealistic face images from 3DMM rendered faces of different identities with arbitrary poses, expressions, and illuminations.
    - 本論文では、任意のポーズ・表情・照明をもつ、異なるアイデンティティの3DMMでレンダリングされた顔から、フォトリアリスティックな顔画像を生成するという課題に取り組みます。

- We formulate this problem as a domain adaptation problem i.e. aligning the 3DMM rendered face domain into realistic face domain.
    - この問題をドメイン適応問題として定式化する。
    - 即ち、３ＤＭＭレンダリングされた顔ドメインを現実的な顔ドメインに整列させること。

- One of the previous works closest to ours [22] address style transfer problem between a pair of domains with classical conditional GAN.
    - 我々の手法に最も近い以前の研究は、古典的なcGANで一対のドメイン間の style transfer に取り組み。

- The major bottleneck of this method is, it requires a large number of paired examples from both domains which are hard to collect.
    - この方法の主なボトルネックは、収集が困難な両方のドメインから多数のペアの例を必要とすることです。

- CycleGAN [63], another recent method and closest to our work, proposes a two-way GAN framework for unsupervised image-to-image translation.
    - CycleGAN [63] は、も我々の研究に最も近い最近の方法の別の１つで、教師なしの image-to-image 変換のための双方向GANフレームワークを提案します。

- However, the cycle consistency loss proposed in their method is satisfied as long as the transitivity of the two mapping networks is maintained.
    - しかしながら、それらの方法において提案された cycle consistency loss は、２つのマッピングネットワークの転移性が維持される限り満足される。

- Thus, the resulting mapping is not guaranteed to produce the intended transformation.
    - したがって、結果として得られるマッピングが意図した変換を生成することは保証されません。

- To overcome the drawbacks of these methods [22,63], we propose to use a small amount of paired data to train an inverse mapping network as a matching aware discriminator.
    - **これらの方法の欠点を克服するために[22] [63]、マッチング対応識別器 [matching aware discriminator] として逆写像ネットワークを訓練するために少量の対データを使用することを提案する。**

- In the proposed method, the inverse mapping network plays the role of both the generator and the discriminator.
    - **提案手法では、逆写像ネットワークが生成器と識別器の両方の役割を果たす。**

- To the best of our knowledge, this is the first attempt for adversarial semi-supervised style translation for an application with such limited paired data.
    - 私たちの知る限りでは、これはそのような限られた対データを持つアプリケーションのための敵対的半教師付き Style Transfer の最初の試みです。

---

- Adding realism to the synthetic face images and preserving their identity information is a challenging problem.
    - 合成顔画像にリアリズムを追加し、それらの識別情報を保存することは困難な問題である。

- Although synthetic input images, 3DMM rendered faces, contain distinct face identities, the distinction between them vanishes as a result of the virtue of non-linear transformations while the discriminator encourages realism.
    - 合成入力画像、３ＤＭＭレンダリングされた顔は、全く別の [distinct] 顔の同一性を含むが、
    - それらの間の区別は、識別器がリアリズムを奨励する一方で、非線形変換のおかげで [virtue of] 消滅する。
    
- To tackle such problem, prior works either employ a separate pre-trained network [57] or embed Identity labels (id) [46] into the discriminator.
    - そのような問題に取り組むために、これまでの研究では、事前学習された別れた [separate] ネットワーク[57]を使用するか、識別器に識別ラベル（id）[46]を埋め込んでいます。

- Unlike existing works, which are focused on generating new images of existing identities, we are interested in generating multiple images of new identities itself. 
    - 既存のアイデンティティの新しい画像を生成することに焦点を当てている既存の研究とは異なり、私たちは新しいアイデンティティの複数の画像自体を生成することに興味を持っています。

- Therefore, such techniques are not directly applicable to our problem.
    - したがって、そのようなテクニックは、私たちの問題に直接適用することはできません。

- To address this challenge, we propose to use set-based center [50] and pushing loss functions [16] on top of a pre-trained face embedding network.
    - この課題に取り組むために、我々は事前学習された顔埋め込みネットワークの上に、set-based center [50]および pushing loss functions [16]を使用することを提案する。

- This will keep track of the changing average of embeddings of generated images belonging to same identity (i.e. centroids).
    - これは、同一のアイデンティティに属する生成された画像の埋め込みの変化する平均（すなわち重心）を追跡するであろう。

- In this way identity preservation becomes adaptive to changing feature space during the training of the generator network unlike softmax layer that converges very quickly at the beginning of the training before meaningful images are generated.
    - このように、アイデンティティ保存は、意味のある画像が生成される前に、学習の開始時に非常に早く収束するソフトマックス層とは異なり、ジェネレータネットワークの学習中に変化する特徴空間に適応するようになる。

---

- Our contributions can be summarized as follows:

- We propose a novel end-to-end adversarial training framework to generate photorealistic face images of new identities constrained by synthetic 3DMM images with identity, pose, illumination and expression diversity. The resulting synthetic face images are visually plausible and can be used to boost face recognition as additional training data or any other graphical purposes.
    - アイデンティティ、ポーズ、照明と表情の多様性を持つ合成3DMM画像によって制約された新しいアイデンティティの写実的な顔画像を生成するための新しい end-to-end の敵対的学習フレームワークを提案する。 
    - 結果として生じる合成顔画像は視覚的にもっともらしく、追加の学習用データまたは他の任意のグラフィック目的として顔認識を高めるために使用することができる。

- We propose a novel semi-supervised adversarial style transfer approach that trains an inverse mapping network as a discriminator with paired synthetic-real images.
    - ペア付けされた合成本物画像を持つ識別器として、逆写像ネットワークを学習する新しい半教師つき敵対的 style transfer アプローチを提案する。

- We employ a novel set-based loss function to preserve consistency among unknown identities during GAN training.
    - **我々は、GANトレーニング中に未知のアイデンティティ間の一貫性を保つために、新しい set-based loss function を採用しています。**

# ■ 結論

## x. 論文の項目名 (Conclusion)


# ■ 何をしたか？詳細

## 3 Adversarial Identity Generation

- In this Section, we describe in details the proposed method.

- Fig. 1 shows the detailed schematic diagram of our method.

- Specifically, the synthetic image set x ∈ S is formed by a graphical engine for the randomly sampled 3DMM, pose and lighting parameters α. 
    - 具体的には、合成画像セットｘ∈Ｓは、ランダムにサンプリングされた３ＤＭＭ、姿勢および照明パラメータαのためのグラフィカルエンジンによって形成される。

- Then they are translated into more photorealistic domain G(x) through the network G and mapped back to synthetic domain (G′(G(x))) through the network G′ to retain x.
    - 次に、それらは、ネットワークGを介してより写実的なドメインG（x）に変換され、ネットワークG 'を介して合成ドメイン（G'（G（x）））にマッピングされてxを保持する。

- Adversarial synthetic and real domain translation of G and G′ networks are supervised by the discriminator networks DR and DS , with an additional adversarial game between G and G′ as generator and discriminator respectively.
    - GおよびG 'ネットワークの敵対的合成および実ドメイン変換は、識別器ネットワークDRおよびDSによって監督され、GおよびG'間の追加の敵対的ゲームがそれぞれ生成器および識別器として行われる。

- During training, generated identities by 3DMM is preserved with a set-based loss on a pre-trained embedding network C.
    - トレーニング中、３ＤＭＭによって生成されたアイデンティティは、事前学習された埋め込みネットワークＣ上で set-based loss で保存される。

- In the following subsections, we further describe these components i.e. domain adaptation, real-synthetic pair discriminator, and identity preservation.
    - 以下のサブセクションでは、これらの構成要素、すなわちドメイン適応、実合成ペア識別子、およびアイデンティティ保存についてさらに説明する。

---

![image](https://user-images.githubusercontent.com/25688193/61192596-8679c580-a6f0-11e9-97bd-78f207a47279.png)

- > Fig. 1: Our approach aims to synthesize photorealistic images conditioned by a given synthetic image by 3DMM.
    - > 図１：我々のアプローチは、３ＤＭＭによって与えられた合成画像で条件付けされた写実的な画像を合成することを目的としている。

- > It regularizes cycle consistency [63] by introducing an additional adversarial game between the two generator networks in an unsupervised fashion.
    - > それは、教師なし形式で、2つのジェネレータネットワークの間に追加の敵対的なゲームを導入することによって cycle consistency  を正則化する[63]。

> CycleGAN の cycle consistency

- > Thus the under-constraint cycle loss is supervised to have correct matching between the two domains by the help of a limited number of paired data.
    - > したがって、制限されていないサイクル損失は、限られた数のペア付けされたデータの助けを借りることによって、2つのドメイン間で、正しく一致するように管理されます。

- > We also encourage the generator to preserve face identity by a set-based supervision through a pretrained classification network.
    - > 私達はまた生成器が、事前学習された分類ネットワークを通して、集合ベースの監査？ [set-based supervision] によって、顔のアイデンティティを保存することを促進します。

### 3.1 Unsupervised Domain Adaptation

- Given a 3D morphable model (3DMM) [3], we synthesize face images of new identities sampled from its Principal Components Analysis (PCA) coefficients’ space with random variation of expression, lighting and pose.
    - 3Dモーファブルモデル（3DMM）[3]を与えれば、主成分分析（PCA）係数の空間から、表現・照明・ポーズをランダムに変化させて、サンプリングした新しいアイデンティティの顔画像を合成します。

- Similar to [63], a synthetic input image (x ∈ S) is mapped to photorealistic domain by a residual network (G : S → Rˆ) and mapped back to synthetic domain by a 3DMM fitting network (G′ : Rˆ → Sˆ) to complete forward cycle only.
    - CycleGAN ［63］と同様にして、順方向サイクルのみを完了するために、
    - 合成入力画像（ｘ∈Ｓ）は、残差ネットワーク（Ｇ：Ｓ→Ｒ ＾）によって写実的ドメインに写像され、
    - ３ＤＭＭフィッティングネットワーク（Ｇ '：Ｒ ＾→Ｓ ＾）によって合成ドメインに写像される。 

- To preserve cycle consistency, the resulting image G′(G(x)) is encouraged to be the same as input x by a pixel level L1 loss:
    - サイクルの一貫性を保つために、結果として生じる画像Ｇ '（Ｇ（ｘ））は、画素レベルＬ１損失によって入力ｘと同じであることが推奨される。

![image](https://user-images.githubusercontent.com/25688193/61195461-1c1e5080-a703-11e9-8cd6-1e600d8e8e97.png)


---

- In order to encourage the resulting images G(x) and G′(G(x)) to have similar distribution as real and synthetic domains respectively, those refiner networks are supervised by discriminator networks DR and DS with images of the respective domains.
    - 結果として生じる画像Ｇ（ｘ）およびＧ '（Ｇ（ｘ））がそれぞれ実ドメインおよび合成ドメインと同様の分布を有するように促すために、それらのリファイナネットワークは、それぞれのドメインの画像と共に弁別ネットワークＤＲおよびＤＳによって監視される。

- The discriminator networks are formed as auto-encoders as in boundary equilibrium GAN (BEGAN) architecture [2] in which the generator and discriminator networks are trained by the following adversarial training formulation:
    - 弁別器ネットワークは、境界平衡GAN（BEGAN）アーキテクチャ[2]のようにオートエンコーダとして形成されます。
    - このアーキテクチャでは、ジェネレータネットワークと識別器ネットワークは、次の敵対者学習での定式化によって学習されます。

![image](https://user-images.githubusercontent.com/25688193/61195477-36f0c500-a703-11e9-9ec2-38aa1fe83f57.png)

- where for each training step t and the network G we update the balancing term with ![image](https://user-images.githubusercontent.com/25688193/61195714-d06ca680-a704-11e9-99c3-276c12035c21.png).

- As suggested by [2], this term helps to balance between generator and discriminator and stabilize the training.


### 3.2 Adversarial Pair Matching

- Cycle consistency loss ensures bijective transitivity of functions G and G′ which means generated image G(x) ∈ Rˆ should be transformed back to x ∈ Sˆ.
    - 周期の一貫性の損失は、関数GとG 'の全単射 [bijective] 推移性を保証します。これは、生成された画像G（x）∈R ˆをx∈S ˆに変換し直す必要があることを意味します。

- Convolutional networks are highly under-constrained and they are free to make any unintended changes as long as the cycle consistency is satisfied.
    - 畳み込みネットワークは非常に制約が少なく、サイクルの一貫性が満たされている限り、意図しない変更を自由に行うことができます。

- Therefore, without additional supervision, it is not guaranteed to achieve the correct mapping that preserves shape, texture, expression, pose and lighting attributes of the face image from domains S to Rˆ and Rˆ to Sˆ.
    - したがって、追加の監督なしには、ドメインＳからＲ ＾およびＲ ＾からＳ ＾から顔画像の形状、テクスチャ、表情、姿勢および照明属性を保存する正しいマッピングを達成することは保証されない。

- This problem is often addressed by introducing pixel-level penalization between input and output of the networks [63,42] which is sub-optimal for domain adaptation as it encourages to stay in the same domain.
    - この問題は、ネットワークの入力と出力との間にピクセルレベルのペナルティを導入することによって対処されることが多く[63、42]、これは同じドメインに留まることを奨励するので、ドメイン適応には最適ではない。

---

- To overcome this issue, we propose an additional pair-wise adversarial loss that assign G′ network an additional role as a pair-wise discriminator to supervise G network.

- Given a set of paired synthetic and real images (PS , PR ), the discriminator loss is computed by BEGAN as follows:

![image](https://user-images.githubusercontent.com/25688193/61196060-3823f100-a707-11e9-86d7-497d3e322db2.png)

---

- While G′ network is itself a generator network (G′ : Rˆ → Sˆ) with a separate discriminator (DS), we use it as a third pair-matching discriminator to supervise G by means of distribution of paired correspondence of real and synthetic images.

- Thus while cycle-loss optimizes for biject correspondence, we expect resulting pairs of (x ∈ S,G(x) ∈ Rˆ) to have similar correlation distribution as paired training data (s ∈ PS,r ∈ PR).

- Fig 2 shows its relation to the previous related arts and comparison to an alternative which is matching aware discriminator with paired inputs for text to image synthesis as suggested by [36].

- Please notice that how BEGAN autoencoder architecture is utilized to align the distribution of pair of synthetic and real images with synthetic and generated images.


### 3.3 Identity Preservation

### Full Objective


# ■ 実験結果（主張の証明）・議論（手法の良し悪し）・メソッド（実験方法）

## x. 論文の項目名


# ■ 関連研究（他の手法との違い）

## x. 論文の項目名（Related Work）


