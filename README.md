# MachineLearning-Papers_Survey
機械学習関連の論文（arXiv等）読み練習用レポジトリ

## ■ 構成

- Deep Neural Network
    - [[ResNet] Deep Residual Learning for Image Recognition](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Deep_Residual_Learning_for_Image_Recognition/ResNet.md)
    - [Kervolutional Neural Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Kervolutional_Neural_Networks/Kervolutional_Neural_Networks.md)
- GNN
    - [Semi-supervised Learning with Graph Learning-Convolutional Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Semi-supervised_Learning_with_Graph_Learning-Convolutional_Networks/Semi-supervised_Learning_with_Graph_Learning-Convolutional_Networks.md)
- VAE
    - [[VAE] Auto-Encoding Variational Bayes](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Auto-Encoding_Variational_Bayes/VAE.md)
    - [【翻訳中】[CVAE] Learning Structured Output Representation using Deep Conditional Generative Models](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Learning_Structured_Output_Representation_using_Deep_Conditional_Generative_Models/CVAE.md)
- GANs
    - [[GAN] Generative Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Generative_Adversarial_Networks/GenerativeAdversarialNetworks.md)
    - [[DCGAN] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Unsupervised_Representation_Learning_with_Deep_Convolutional_Generative_Adversarial_Networks/DeepConvolutionalGAN.md)
    - [[cGAN] Conditional Generative Adversarial Nets](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Conditional_Generative_Adversarial_Nets/ConditionalGAN.md)
    - [[WGAN] Wasserstein GAN](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Wasserstein_GAN/WassersteinGAN.md)
    - [[pix2pix] Image-to-Image Translation with Conditional Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Image-to-Image_Translation_with_Conditional_Adversarial_Networks/pix2pix.md)
    - [【翻訳中】[pix2pix-HD] High-Resolution_Image_Synthesis_and_Semantic_Manipulation_with_Conditional_GANs](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/High-Resolution_Image_Synthesis_and_Semantic_Manipulation_with_Conditional_GANs/pix2pix-HD.md)
    - [SAGAN [Self-Attention Generative Adversarial Networks]](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Self-Attention_Generative_Adversarial_Networks/SAGAN.md)
    - [[PGGAN] Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Progressive_Growing_of_GANs_for_Improved_Quality_Stability_and_Variation/ProgressiveGAN.md)
    - [[CycleGAN] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks/CycleGAN.md)
    - [[StarGAN] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/StarGAN_Unified_Generative_Adversarial_Networks_for_Multi-Domain_Image-to-Image_Translation/StarGAN.md)
    - [[StyleGAN] A Style-Based Generator Architecture for Generative Adversarial Networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks/StyleGAN.md)
    - [【翻訳中】[Image2StyleGAN] Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space?](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space?/Image2StyleGAN.md)
    - [[SPADE] Semantic Image Synthesis with Spatially-Adaptive Normalization](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Semantic_Image_Synthesis_with_Spatially-Adaptive_Normalization/SPADE.md)
- Semantic Segmentation
    - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/U-Net_Convolutional_Networks_for_Biomedical/UNet.md)
    - [Graphonomy: Universal Human Parsing via Graph Transfer Learning](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Graphonomy_Universal_Human_Parsing_via_Graph_Transfer_Learning/Graphonomy.md)
- Style Transfer
    - [【翻訳中】Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Perceptual_Losses_for_Real-Time_Style_Transfer_and_Super-Resolution/Perceptual_Losses_for_Real-Time_Style_Transfer_and_Super-Resolution.md)
- Inpainting
    - [Pluralistic Image Completion](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Pluralistic_Image_Completion/Pluralistic-Inpainting.md)
- 顔特化系（Face Swap, etc）
    - [[GANimation] GANimation: Anatomically-aware Facial Animation from a Single Image](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/GANimation_Anatomically-aware_FacialAnimation_from_a_Single_Image/GANimation.md)
    - [【翻訳中】[FaceGAN] Semi-supervised Adversarial Learning to Generate Photorealistic Face Images of New Identities from 3D Morphable Model](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Semi-supervised_Adversarial_Learning_to_Generate_Photorealistic_Face_Images_of_New_Identities_from_3D_Morphable_Model/FaceGAN.md)
    - [【翻訳中】On Face Segmentation, Face Swapping, and Face Perception](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/On%20Face%20Segmentation%2C%20Face%20Swapping%2C%20and%20Face%20Perception/FaceSwap.md)
    - [Face Swapping: Realistic Image Synthesis Based on Facial Landmarks Alignment](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Face_Swapping_Realistic_Image_Synthesis_Based_on_Facial_Landmarks_Alignment/FaceSwap.md)
- Virtual Try-On
    - [[CP-VTON] Toward Characteristic-Preserving Image-based Virtual Try-On Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Toward_Characteristic-Preserving_Image-based_Virtual_Try-On_Network/cp-vton.md)
    - [[MG-VTON] Towards_Multi-pose_Guided_Virtual_Try-on_Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Towards_Multi-pose_Guided_Virtual_Try-on_Network/MG-VTON.md)
- 触覚・知覚系
    - [[TackGAN] Vibrotactile Signal Generation from Texture Images or Attributes using Generative Adversarial Network](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/TackGAN/TackGAN.md)
    - [【翻訳中】Learning cross-modal visual-tactile representation using ensembled generative adversarial networks](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Learning_cross_modal_visual_tactile_representation_using_ensembled_generative_adversarial_networks/Learning_cross_modal_visual_tactile_representation_using_ensembled_generative_adversarial_networks.md)
    - [【翻訳中】Presenting Static Friction Sensation at Stick-slip Transition using Pseudo-haptic Effect](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Presenting_Static_Friction_Sensation_at_Stick_slip_Transition_using_Pseudo_haptic_Effect/Presenting_Static_Friction_Sensation_at_Stick_slip_Transition_using_Pseudo_haptic_Effect.md)
    - [【翻訳中】Authoring New Haptic Textures Based on Interpolation of Real Textures in Affective Space](https://github.com/Yagami360/MachineLearning-Papers_Survey/blob/master/papers/Authoring%20New%20Haptic%20Textures%20Based%20on%20Interpolation%20of%20Real%20Textures%20in%20Affective%20Space/Authoring%20New%20Haptic%20Textures%20Based%20on%20Interpolation%20of%20Real%20Textures%20in%20Affective%20Space.md)
- Others
    - xxx

## ■ 参考サイト

### ◎ 論文サイト
- [arXiv](https://arxiv.org/)
- [Google Scholer](https://scholar.google.co.jp/schhp?hl=ja&as_sdt=0,5)

### ◎ 便利サイト
- [Google翻訳](https://translate.google.co.jp/?hl=ja&tab=wT)
- [papers with code](https://paperswithcode.com/)
    - 論文実装の有無を確認できる。    
- [Hyper Collocation](https://hypcol.marutank.net/ja/)
- [arXiv Vanity](https://www.arxiv-vanity.com/)


### ◎ その他参考サイト

- [arXivTimes](https://github.com/arXivTimes/arXivTimes)
- [ymym3412/acl-papers](https://github.com/ymym3412/acl-papers)
- [shunk031/paper-survey](https://github.com/shunk031/paper-survey)
- [趣味として楽しむ論文読みのススメ - karaage. [からあげ]](https://karaage.hatenadiary.jp/entry/2018/08/13/000000)


## ■ 論文要約フォーマット（短いバージョン）

```
layout: post

title:  "論文タイトル"

date:   YYYY-MM-DD

categories: CV NLP Others

## 1. どんなもの？

## 2. 先行研究と比べてどこがすごいの？

## 3. 技術や手法の"キモ"はどこにある？

![Figure 1]({{ site.baseurl }}/assets/img/(cv, nlp, others)/(title)/figure1.png)

## 4. どうやって有効だと検証した？

## 5. 議論はあるか？

## 6. 次に読むべき論文はあるか？

### 論文情報・リンク

* [著者，"タイトル，" ジャーナル名，voluem，no.，ページ，年](論文リンク)

```
- [先端技術とメディア表現1 #FTMA15](http://www.slideshare.net/Ochyai/1-ftma15) from [Yoichi Ochiai](http://www.slideshare.net/Ochyai)

![](https://raw.githubusercontent.com/shunk031/paper-survey/master/assets/img/FTMA15-1-page-65.png)

<br>

```
## 一言でいうと

### 論文リンク

### 著者/所属機関

### 投稿日付(yyyy/MM/dd)

## 概要

## 新規性・差分

## 手法

## 結果

## コメント
```

